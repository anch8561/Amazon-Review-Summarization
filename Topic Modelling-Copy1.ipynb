{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF,  LatentDirichletAllocation\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "\n",
    "from nltk import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "import spacy\n",
    "import gzip\n",
    "import simplejson as json\n",
    "import nltk\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import os\\nimport gzip\\nimport json\\n\\ndef parse(path):\\n    g = gzip.open(path, 'r')\\n    for l in g:\\n        yield json.loads(l)\\n\\nfileName = 'Electronics_5'\\ninputFileName  = fileName + '.json.gz'\\nif not os.path.exists(fileName): os.makedirs(fileName)\\n\\ncount = 0\\nii = 0\\ndata = {}\\nasin = '0'\\nfor review in parse(inputFileName):\\n    if review['asin'] != asin:\\n        outputFileName = fileName + r'/' + asin + '.json'\\n        outputFile = open(outputFileName, 'w', newline='')\\n        json.dump(data, outputFile)\\n        outputFile.close\\n        ii = 0\\n        data = {}\\n        asin = review['asin']\\n    try: helpfulness = review['vote']\\n    except: helpfulness = '0'\\n    try:\\n        data[ii] = {\\n            'helpfulness': helpfulness,\\n            'rating': review['overall'],\\n            'text': review['reviewText']}\\n        ii += 1\\n    except: pass\\n    count += 1\\n    if count % 1e5 == 0: print(count)\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Script for SAVING DATA. Uncomment it when needed\n",
    "\n",
    "\"\"\"import os\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'r')\n",
    "    for l in g:\n",
    "        yield json.loads(l)\n",
    "\n",
    "fileName = 'Electronics_5'\n",
    "inputFileName  = fileName + '.json.gz'\n",
    "if not os.path.exists(fileName): os.makedirs(fileName)\n",
    "\n",
    "count = 0\n",
    "ii = 0\n",
    "data = {}\n",
    "asin = '0'\n",
    "for review in parse(inputFileName):\n",
    "    if review['asin'] != asin:\n",
    "        outputFileName = fileName + r'/' + asin + '.json'\n",
    "        outputFile = open(outputFileName, 'w', newline='')\n",
    "        json.dump(data, outputFile)\n",
    "        outputFile.close\n",
    "        ii = 0\n",
    "        data = {}\n",
    "        asin = review['asin']\n",
    "    try: helpfulness = review['vote']\n",
    "    except: helpfulness = '0'\n",
    "    try:\n",
    "        data[ii] = {\n",
    "            'helpfulness': helpfulness,\n",
    "            'rating': review['overall'],\n",
    "            'text': review['reviewText']}\n",
    "        ii += 1\n",
    "    except: pass\n",
    "    count += 1\n",
    "    if count % 1e5 == 0: print(count)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield json.loads(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "\n",
    "class CleanTextTransformer(TransformerMixin):\n",
    "   \n",
    "    def transform(self, X, **transform_params):\n",
    "        #return [cleanText(text) for text in X]\n",
    "        return [text for text in X]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "    \n",
    "\"\"\"def cleanText(text):\n",
    "    \"this function removes new lines.\"\n",
    "    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    return text\n",
    "\"\"\"\n",
    "\n",
    "def tokenizeText(sample):\n",
    "    \"This function tokenizes text and does other preprocessing steps like Lemmatization and Stemming.\"\n",
    "\n",
    "    tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    #tokenize\n",
    "    tokens = tokenizer.tokenize(sample)\n",
    "    # lemmatize\n",
    "    lemmas = []\n",
    "    for word in tokens:\n",
    "        if word.isalnum() and not word in stop_words:\n",
    "            word = word.lower()\n",
    "            word = lemmatizer.lemmatize(word, pos = 'v')\n",
    "            lemmas.append(word)\n",
    "    tokens = lemmas\n",
    "    # white space removal and new line removal\n",
    "    while \"\" in tokens:\n",
    "        tokens.remove(\"\")\n",
    "    while \" \" in tokens:\n",
    "        tokens.remove(\" \")\n",
    "    while \"\\n\" in tokens:\n",
    "        tokens.remove(\"\\n\")\n",
    "    while \"\\n\\n\" in tokens:\n",
    "        tokens.remove(\"\\n\\n\")\n",
    "\n",
    "    return tokens\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "def return_topics(vectorizer, clf, W, df, n_top_words, n_top_documents):\n",
    "    print('return topics')\n",
    "    topics, reviews = [], []\n",
    "    features = vectorizer.get_feature_names()\n",
    "    sentiment_analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "    for topic_id, topic in enumerate(clf.components_):\n",
    "\n",
    "        # grab the list of words describing the topic\n",
    "        topic_word_list = []\n",
    "        for i in topic.argsort()[:-n_top_words - 1:-1]:\n",
    "            topic_word_list.append(features[i])\n",
    "\n",
    "        # split words in case there are some bigrams\n",
    "        split_topic_word_list = []\n",
    "        for word in topic_word_list:\n",
    "            for splitted in word.split():\n",
    "                split_topic_word_list.append(splitted)\n",
    "        topic_words = list(set(split_topic_word_list))\n",
    "\n",
    "        # append topic words as a single string\n",
    "        topics.append(' '.join([word for word in topic_words]))\n",
    "\n",
    "        # iterate for reviews for each topic\n",
    "        topic_doc_indices = np.argsort(W[:, topic_id])[::-1][0:n_top_documents]\n",
    "\n",
    "        for doc_ind in topic_doc_indices:\n",
    "            review = df['reviewText'].iloc[doc_ind]\n",
    "\n",
    "            # check if the review contains any of the topic words\n",
    "            if any(word in review.lower() for word in topic_words):\n",
    "                # analyse sentiment\n",
    "                vader = sentiment_analyser.polarity_scores(review)\n",
    "                # form the review - topic_id and sentiment data structure\n",
    "                reviews.append(df.iloc[doc_ind].to_dict())\n",
    "                reviews[-1]['topic'] = topic_id\n",
    "                reviews[-1]['sentiment'] = vader['compound']\n",
    "\n",
    "    return topics, reviews\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "def summarize_reviews(topics, reviews):\n",
    "    # topics: list of strings. Each string contains the topics for a review\n",
    "    # reviews: list of dicts with the following fields\n",
    "    #  'reviewText': string with text of the review\n",
    "    #  'topic': topics index\n",
    "    # returns reviews with the following new fields\n",
    "    #  'summary': sentences from review w/ topic words\n",
    "\n",
    "    analyser = SentimentIntensityAnalyzer()\n",
    "    summary_all_review = []\n",
    "    for ii, review in enumerate(reviews):\n",
    "        summary = []\n",
    "        sentences = sent_tokenize(review['reviewText'])\n",
    "        topic_words = topics[review['topic']].split()\n",
    "\n",
    "        for sentence in sentences:\n",
    "            for word in topic_words:\n",
    "                if word in sentence.lower():\n",
    "                    summary.append(sentence)\n",
    "                    break\n",
    "\n",
    "        reviews[ii]['summary'] = ' '.join([sentence for sentence in summary])\n",
    "        vader = analyser.polarity_scores(reviews[ii]['summary'])\n",
    "        reviews[ii]['summary_sentiment'] = vader['compound']\n",
    "        \n",
    "        summary_all_review.append(reviews[ii]['summary'])\n",
    "\n",
    "    return reviews, summary_all_review\n",
    "\n",
    "def print_topics(test_asin):\n",
    "\n",
    "    test_df = reviews_df[reviews_df['asin'] == test_asin].dropna()\n",
    "    n_features, n_top_words, n_topics, n_top_documents = 1000, 3, 8, 3\n",
    "\n",
    "    vectorizer = TfidfVectorizer(max_features=n_features,\n",
    "                                 tokenizer=tokenizeText,\n",
    "                                 stop_words='english',\n",
    "                                 ngram_range=(1,2))\n",
    "\n",
    "    clf = NMF(n_components=n_topics, random_state=1, solver='mu', beta_loss='frobenius')\n",
    "   \n",
    "    #clf = LatentDirichletAllocation(n_components = 5, max_iter = 5, learning_method ='online',learning_offset = 50.,random_state = 0)\n",
    "\n",
    "    pipe = Pipeline([('cleanText', CleanTextTransformer()),('vectorizer', vectorizer), ('nmf', clf)])\n",
    "\n",
    "    pipe.fit(test_df['reviewText'])\n",
    "    transform = pipe.fit_transform(test_df['reviewText'])\n",
    "    \n",
    "    #topic identification\n",
    "    topics, reviews = return_topics(vectorizer, clf, transform, test_df, n_top_words, n_top_documents)\n",
    "    # review summarization\n",
    "    reviews , summary = summarize_reviews(topics, reviews)\n",
    "    print(\"Summary :\\n\", len(summary))\n",
    "    print(\"Topics:\", len(topics))\n",
    "    \n",
    "    return topics, reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       reviewerID        asin              reviewerName   helpful  \\\n",
      "0   AO94DHGC771SJ  0528881469                   amazdnu    [0, 0]   \n",
      "1   AMO214LNFCEI4  0528881469           Amazon Customer  [12, 15]   \n",
      "2  A3N7T0DY83Y4IG  0528881469             C. A. Freeman  [43, 45]   \n",
      "3  A1H8PY3QHMQQA0  0528881469  Dave M. Shaw \"mack dave\"   [9, 10]   \n",
      "\n",
      "                                          reviewText  overall  \\\n",
      "0  We got this GPS for my husband who is an (OTR)...      5.0   \n",
      "1  I'm a professional OTR truck driver, and I bou...      1.0   \n",
      "2  Well, what can I say.  I've had this unit in m...      3.0   \n",
      "3  Not going to write a long review, even thought...      2.0   \n",
      "\n",
      "                   summary  unixReviewTime   reviewTime  \n",
      "0          Gotta have GPS!      1370131200   06 2, 2013  \n",
      "1        Very Disappointed      1290643200  11 25, 2010  \n",
      "2           1st impression      1283990400   09 9, 2010  \n",
      "3  Great grafics, POOR GPS      1290556800  11 24, 2010  \n"
     ]
    }
   ],
   "source": [
    "#reviews_df = getDF('Video_Games_5.json.gz')\n",
    "reviews_df = getDF('Electronics_5.json.gz')\n",
    "print(reviews_df.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_entropy(n):\n",
    "    return -np.log(1/n)\n",
    "\n",
    "def unique(sequence):\n",
    "    '''get unique elements of list and keep the same order'''\n",
    "    \n",
    "    seen = set()\n",
    "    return [x for x in sequence if not (x in seen or seen.add(x))]\n",
    "\n",
    "def redundancy(string):\n",
    "    entropy, string_list = 0, string.split()\n",
    "    string_set = unique(string_list)\n",
    "    for word in string_set:\n",
    "        p = string_list.count(word)/len(string_list)\n",
    "        entropy -= p*np.log(p)        \n",
    "    return 1 - entropy/max_entropy(len(string_list))\n",
    "\n",
    "def lemmatize(string):\n",
    "    from nltk.stem import PorterStemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = parser(string)\n",
    "    lemmas = []\n",
    "    for token in tokens:\n",
    "        lemmas.append(stemmer.stem(token.lemma_.lower().strip()))\n",
    "        \n",
    "    return ' '.join(lemma for lemma in lemmas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speaker system sound quality headphone jack satellite speakers sound card highly recommend thx certify midrange bang buck live room home theater altec lansing\n",
      "0.019223019952826492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      "['bass sound music', '2300 z', 'great sound', 'buy speakers computer', 'remote satellite cable', 'sound good card', 'work great bose', 'speaker best set']\n",
      "bass sound music 2300 z great sound buy speakers computer remote satellite cable sound good card work great bose speaker best set\n",
      "0.06885190025657495\n"
     ]
    }
   ],
   "source": [
    "string = 'speaker system sound quality headphone jack satellite speakers sound card highly recommend thx certified midrange bang for the buck living room home theater altec lansing'\n",
    "lemmas = tokenizeText(string) \n",
    "lemmas = ' '.join(lemma for lemma in lemmas)\n",
    "print(lemmas)\n",
    "print(redundancy(lemmas))\n",
    "\n",
    "topics, reviews = print_topics('B0002SQ2P2')\n",
    "\n",
    "print(topics)\n",
    "# print(emoji_topics)\n",
    "lemmas = ' '.join(lemma for lemma in topics)\n",
    "print(lemmas)\n",
    "print(redundancy(lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earbuds sound quality couple months every 6 months sound good great sound bass volume ears earbud earphones hear inexpensive jack model break cord\n",
      "0.06492466861659307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      "['headphones sound music', 'years home studio', 'head wear ears', 'comfortable great', 'flat hz response', 'price expect feel', 'read review say', 'amp headphone fit']\n",
      "headphones sound music years home studio head wear ears comfortable great flat hz response price expect feel read review say amp headphone fit\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "string = 'earbuds sound quality couple months every 6 months sound was good great sound bass volume ears earbud earphones hear inexpensive jack model broke cord'\n",
    "lemmas = tokenizeText(string) \n",
    "lemmas = ' '.join(lemma for lemma in lemmas)\n",
    "print(lemmas)\n",
    "print(redundancy(lemmas))\n",
    "\n",
    "\n",
    "\n",
    "topics, review = print_topics('B0002D03ZW')\n",
    "print(topics)\n",
    "lemmas = ' '.join(lemma for lemma in topics)\n",
    "print(lemmas)\n",
    "print(redundancy(lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def grid_search_topic_model(test_asin):\n",
    "    search_params = {'n_components': [3,4,5,6,7,8,9,10,11,12], \"solver\": ['cd','mu']}\n",
    "    test_df = reviews_df[reviews_df['asin'] == test_asin].dropna()\n",
    "    n_features, n_top_words, n_topics, n_top_documents = 1000, 3, 6, 3\n",
    "    vectorizer = TfidfVectorizer(max_features=n_features,\n",
    "                                 tokenizer=tokenizeText,\n",
    "                                 stop_words='english',\n",
    "                                 ngram_range=(1,2))\n",
    "\n",
    "    clf = NMF()\n",
    "\n",
    "    pipe = Pipeline([('cleanText', CleanTextTransformer()),('vectorizer', vectorizer)])\n",
    "\n",
    "    # pipe.fit(test_df['reviewText'])\n",
    "    data_vectorized = pipe.fit_transform(test_df['reviewText'])\n",
    "\n",
    "    model = GridSearchCV(clf, param_grid=search_params)\n",
    "\n",
    "    model.fit(data_vectorized)\n",
    "    best_topic_model = model.best_estimator_\n",
    "    print(\"Best Model's Params: \", model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "If no scoring is specified, the estimator passed should have a 'score' method. The estimator NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n    n_components=None, random_state=None, shuffle=False, solver='cd',\n    tol=0.0001, verbose=0) does not.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-ece43947f05a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrid_search_topic_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'B0002SQ2P2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-53-d9ae001b0e02>\u001b[0m in \u001b[0;36mgrid_search_topic_model\u001b[1;34m(test_asin)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msearch_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_vectorized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mbest_topic_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best Model's Params: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m         scorers, self.multimetric_ = _check_multimetric_scoring(\n\u001b[1;32m--> 629\u001b[1;33m             self.estimator, scoring=self.scoring)\n\u001b[0m\u001b[0;32m    630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultimetric_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m_check_multimetric_scoring\u001b[1;34m(estimator, scoring)\u001b[0m\n\u001b[0;32m    471\u001b[0m     if callable(scoring) or scoring is None or isinstance(scoring,\n\u001b[0;32m    472\u001b[0m                                                           str):\n\u001b[1;32m--> 473\u001b[1;33m         \u001b[0mscorers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"score\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    474\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m    424\u001b[0m                 \u001b[1;34m\"If no scoring is specified, the estimator passed should \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[1;34m\"have a 'score' method. The estimator %r does not.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m                 % estimator)\n\u001b[0m\u001b[0;32m    427\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m         raise ValueError(\"For evaluating multiple scores, use \"\n",
      "\u001b[1;31mTypeError\u001b[0m: If no scoring is specified, the estimator passed should have a 'score' method. The estimator NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n    n_components=None, random_state=None, shuffle=False, solver='cd',\n    tol=0.0001, verbose=0) does not."
     ]
    }
   ],
   "source": [
    "grid_search_topic_model('B0002SQ2P2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA Best Model's Params:  {'learning_decay': 0.5, 'n_components': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics_lda(test_asin):\n",
    "\n",
    "    test_df = reviews_df[reviews_df['asin'] == test_asin].dropna()\n",
    "    n_features, n_top_words, n_topics, n_top_documents = 1000, 3, 8, 3\n",
    "\n",
    "    vectorizer = TfidfVectorizer(max_features=n_features,\n",
    "                                 tokenizer=tokenizeText,\n",
    "                                 stop_words='english',\n",
    "                                 ngram_range=(1,2))\n",
    "\n",
    "    clf = NMF(n_components=n_topics, random_state=1, solver='mu', beta_loss='frobenius')\n",
    "   \n",
    "    clf = LatentDirichletAllocation(n_components = 3, max_iter = 5, learning_method ='online',learning_offset = 50.,random_state = 0)\n",
    "\n",
    "    pipe = Pipeline([('cleanText', CleanTextTransformer()),('vectorizer', vectorizer), ('nmf', clf)])\n",
    "\n",
    "    pipe.fit(test_df['reviewText'])\n",
    "    transform = pipe.fit_transform(test_df['reviewText'])\n",
    "    \n",
    "    #topic identification\n",
    "    topics, reviews = return_topics(vectorizer, clf, transform, test_df, n_top_words, n_top_documents)\n",
    "    # review summarization\n",
    "    summary = summarize_reviews(topics, reviews)\n",
    "    #print(\"Summary :\\n\", summary)\n",
    "    print(\"Topics:\")\n",
    "    \n",
    "    return topics, reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speaker system sound quality headphone jack satellite speakers sound card highly recommend thx certify midrange bang buck live room home theater altec lansing\n",
      "0.019223019952826492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "['speakers better like', 'speakers sound great', 'bass speakers sound']\n",
      "speakers better like speakers sound great bass speakers sound\n",
      "0.23676997261905086\n"
     ]
    }
   ],
   "source": [
    "string = 'speaker system sound quality headphone jack satellite speakers sound card highly recommend thx certified midrange bang for the buck living room home theater altec lansing'\n",
    "lemmas = tokenizeText(string) \n",
    "lemmas = ' '.join(lemma for lemma in lemmas)\n",
    "print(lemmas)\n",
    "print(redundancy(lemmas))\n",
    "\n",
    "\n",
    "\n",
    "topics, review = print_topics_lda('B0002SQ2P2')\n",
    "print(topics)\n",
    "lemmas = ' '.join(lemma for lemma in topics)\n",
    "print(lemmas)\n",
    "print(redundancy(lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0528881469', '0528881469', '0528881469', '0528881469', '0528881469']\n",
      "['B00030CHRQ', 'B0002Y5WXO', 'B0002IOIMQ', 'B00007M1TZ', 'B00062UW5A', 'B000629GES', 'B0000DJEK7', 'B00006JN3G', 'B0000BYDKO', 'B0001NNLHK', 'B00020S7XK', 'B0002UM0JW', 'B0002UPGOI', 'B0002SQ2P2', 'B00005QXWI', 'B00017LSPI', 'B0000C3GWU', 'B0002D03ZW', 'B0002WPSBC', 'B00028D778', 'B00066EK2W', 'B00004T8R2', 'B0002CZHN6', 'B00004TS16', 'B000204SWE', 'B00009WQS1', 'B00066HP7Y', 'B0000AQIFW', 'B00005NIMJ', 'B00007GQLU', 'B00018MSNI', 'B0002KVQBA']\n",
      "['B00030CHRQ', 'B0002Y5WXO', 'B0002IOIMQ', 'B00007M1TZ', 'B00062UW5A', 'B000629GES', 'B0000DJEK7', 'B00006JN3G', 'B0000BYDKO', 'B0001NNLHK', 'B00020S7XK', 'B0002UM0JW', 'B0002UPGOI', 'B0002SQ2P2', 'B00005QXWI', 'B00017LSPI', 'B0000C3GWU', 'B0002D03ZW', 'B0002WPSBC', 'B00028D778', 'B00066EK2W', 'B00004T8R2', 'B0002CZHN6', 'B00004TS16', 'B000204SWE', 'B00009WQS1', 'B00066HP7Y', 'B0000AQIFW', 'B00005NIMJ', 'B00007GQLU', 'B00018MSNI', 'B0002KVQBA']\n"
     ]
    }
   ],
   "source": [
    "test_amazon_asins = ['B0002SQ2P2', 'B0002KVQBA', 'B00029MTMQ','B00020S7XK','B00063E2HS','B0002D03ZW','B0002WPSBC','B00006JN3G','B0002CZHN6','B00004T8R2','B00004ZCJJ',\n",
    "'B00007M1TZ','B0002UPGOI','B000204SWE','B0002EMY9Y','B00006IAKJ','B000629GES','B00017LSPI','B0002UM0JW',\n",
    "'B0000C3GWU','B0001NNLHK','B0000BYDKO','B00008MOPJ','B00066HP7Y','B0000AQIFW','B00066EK2W','B00005NIMJ',\n",
    "'B00009WQS1','B0000DJEK7','B00028D778','B00030CHRQ','B0002IOIMQ','B0001EMA80','B00006JILE','B0002Y5WXO',\n",
    "'B00062UW5A','B00007GQLU','B00004TS16','B00005QXWI','B00018MSNI']\n",
    "\n",
    "test_elecronics5_asins = reviews_df['asin']\n",
    "print(list(test_elecronics5_asins[:5]))\n",
    "\n",
    "def intersection(lst1, lst2): \n",
    "    return list(set(lst1) & set(lst2))\n",
    "\n",
    "print(intersection(test_amazon_asins, test_elecronics5_asins)) \n",
    "\n",
    "valid_asins = intersection(test_amazon_asins, test_elecronics5_asins)\n",
    "\n",
    "print(valid_asins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      "B00030CHRQ ['extension cord length', 'buy earbuds ears', 'headphones great ear', 'expose coat wire', 'bass buy sony', 'work pull ear', 'price use', 'mp3 player']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      "B0002Y5WXO ['lens kit great', 'zoom light good', 'lense print good', 'canon tamron mm', 'repair problem canon', 'purpose lens general', 'return great amazon', 'heavy picture big']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      "B0002IOIMQ ['4 charge batteries', 'charger good right', 'camera sony batteries', 'life battery', 'display lcd', 'charger fast', 'years use', 'die cells sony']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      "B00007M1TZ ['use headset headsets', 'cordless phone', 'quality sound', 'people hear talk', 'work great', 'volume control', 'set head fit', 'hand free']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      "B00062UW5A ['box snap case', 'sleeves good paper', 'look storage need', 'box cds easy', 'assemble easy', 'price store need', 'pretty discs paper', 'dvd size love']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      "B000629GES ['cancel noise', 'set headphones sony', 'good bose', 'use ears flight', 'work fragile advertise', 'buy product flight long', 'sony headphones pair', 'quality sound ear']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 23\n",
      "Topics: 8\n",
      "B0000DJEK7 ['use unit roadmate', 'extend warranty', 'customer magellan update', 'battery internal', 'device save location', 'wife love door', '2620 disappoint control', 'destination cities job']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      "B00006JN3G ['use lens pen', 'camera bag', 'lenses clean', 'brush dust end', 'use carry easy', 'work product great', 'lens clean', 'good job']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      "B0000BYDKO ['cord reel', 'cable weight reel', 'plug end male', 'work great', 'price like look', '100 cord foot', 'extension cord easy', 'time use cord']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 23\n",
      "Topics: 8\n",
      "B0001NNLHK ['bass listen music', 'supply good fit', 'cord headphones best', 'noise sound block', 'bud hear really', 'seal phone ear', 'price star earphones', 'cover plastic wire']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      "B00020S7XK ['sony radio fm', 'great radio little', 'work fine', 'use power batteries', 'quality sound', 'buy headphones good', 'station little good', 'volume control']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      "B0002UM0JW ['use button mouse', 'mx1000 mx700 surface', 'time wireless track', 'use click original', 'life good battery', 'revolution mx', 'mac charge easy', 'great logitech mouse']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 22\n",
      "Topics: 8\n",
      "B0002UPGOI ['use power wire', 'amp need install', 'work cheap great quality', 'car kit audio', 'awg watts rms', 'price thing great', 'grind length easy', '100 perfect sas bazooka']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      "B0002SQ2P2 ['bass sound music', '2300 z', 'great sound', 'buy speakers computer', 'remote satellite cable', 'sound good card', 'work great bose', 'speaker best set']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 23\n",
      "Topics: 8\n",
      "B00005QXWI ['cd player turn', 'work plate screw', 'mp3 far player rangeit price', 'purchase year little', 'pay make good', '1 3 2', 'accessory know player', '100 90 250']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      "B00017LSPI ['use blow dust', 'compress air', 'work great', 'camera bag', 'clean sensor', 'blaster rocket air', 'blower good say', 'lens dust remove']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      "B0000C3GWU ['quality speakers sound', 'volume control turn', 'work great', 'use great sound', 'mac sound book', 'save feature', 'speakers set sound', 'harman kardon']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      "B0002D03ZW ['headphones sound music', 'years home studio', 'head wear ears', 'comfortable great', 'flat hz response', 'price expect feel', 'read review say', 'amp headphone fit']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      "B0002WPSBC ['speaker speakers sound', 'z 5500', 'price set speakers', 'sound great', 'buy day years', 'home theater', 'customer break send', 'card sound']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      "B00028D778 ['radar detector', 'x50 cord unit', 'cop car drive', 'heat escort service', 'mount better windshield', 'protection know expensive', 'display blue red', 'work years sensitivity']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      "B00066EK2W ['play good player', 'use easy', 'drive hard', 'memory mp3 player', 'music classical', 'come happy 3', '1 v', 'button nice small']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      "B00004T8R2 ['headphones sound pair', 'sound good', 'price work great', 'use cord long', 'recommend highly', 'head fit ear', 'work fine lightweight', 'volume buy quality']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      "B0002CZHN6 ['cable hdmi dvi', 'cable work price', 'laptop monitor computer', 'quality good', 'work great', 'pc connect tv', 'use xbox 360', 'work perfect monitor']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 23\n",
      "Topics: 8\n",
      "B00004TS16 ['use picture camera', 'larger thing card memory', 'quality machine paper', 'work snorkel camera', 'great overall think little camera', 'exposure camera stop', 'glad shoot s100', 'charger reasonable battery especially']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      "B000204SWE ['dvd player', 'divx play file', 'remote region unit', 'play dvds', 'months warranty philips', 'work price great', 'close button hold stop', 'dvp 642']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 23\n",
      "Topics: 8\n",
      "B00009WQS1 ['hard drive', 'work version support', 'ssd usb drive', 'use enclosure upgrade', 'box right', 'dell hdd clone', 'connect screw way', 'partition product like']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 18\n",
      "Topics: 8\n",
      "B00066HP7Y ['sound laptop audio cheep', 'cable headphones audio', 'cable work headphones', 'sound suppose tv', 'cord great stream', 'quite sure bite', 'pc buy car', 'trick ipod electronic thing']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 21\n",
      "Topics: 8\n",
      "B0000AQIFW ['use mp3 player', 'work run rio', 'pretty year hours', 'expandable perfect small', 'sonic device employee', 'product stop', 'know person help', 'rip cd']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 23\n",
      "Topics: 8\n",
      "B00005NIMJ ['work use mouse', 'marble trackman wheel', 'wireless version wire', 'track ball', 'trackball button easy', 'pad thumb mouse', 'years logitech 5', 'thumb button finger']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      "B00007GQLU ['use lens shoot', '85mm f l', 'f1 8', 'lens love', 'purchase lens l', 'lenses image nice', 'light low', 'portraits great lens']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 23\n",
      "Topics: 8\n",
      "B00018MSNI ['cable sound headphone', '650 hd', 'comfortable headphones sound', 'hd650 headphones ears', 'amp tube', 'years ago', 'use like love', 'listen hear music']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      "B0002KVQBA ['bass sound music', '10 psw', 'port want sub', 'great sound', 'rca input subwoofer', 'room live', 'home theater', 'price buy product']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B00030CHRQ ['cord sound sony', 'buy cord use', 'cord design ear']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B0002Y5WXO ['lense lens include', 'lense need mm shoot', 'canon lens good']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B0002IOIMQ ['time problem batteries', 'charger charge batteries', 'charger charge batteries']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B00007M1TZ ['cable hear say', 'use hear clearly', 'use headset phone']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B00062UW5A ['box cd great', 'box use snap', 'case use storage']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B000629GES ['work noise earphones', 'really headphones bose', 'know headphones good ok']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B0000DJEK7 ['gps unit roadmate', 'probably car unit right', 'use model great']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B00006JN3G ['use lens clean', 'lenses clean carry', 'lenspen make wear brush']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B0000BYDKO ['use cord reel', 'use cord reel', 'thing cord junk']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B0001NNLHK ['hear sound listen', 'rubber shure music', 'headphones shure earphones']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B00020S7XK ['work whistle radio', 'today order radio stop', 'great good radio']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B0002UM0JW ['hours months mouse', 'use button mouse', 'charge good mouse']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B0002UPGOI ['work price solution inexpensive', 'box speaker way wire safely', 'excellent say need cut']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B0002SQ2P2 ['speakers better like', 'speakers sound great', 'bass speakers sound']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B00005QXWI ['button year player', 'leather read manuals recharge', 'make player screw produce']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B00017LSPI ['work squeeze blow', 'pfff manual bring', 'use dust air']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B0000C3GWU ['price speakers sound', 'speakers compact', 'work imac speakers']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B0002D03ZW ['use headphones sound', 'headphone record better', 'break warn sound']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B0002WPSBC ['price tigerdirect sound', 'speakers use sound', 'speakers great sound']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B00028D778 ['radar item detector', 'x50 smart claim right', 'years need unit']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B00066EK2W ['use mp3 player', 'rechargeable radio battery issue', 'use mp3 player']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B00004T8R2 ['use headphones sound', 'comfortable bargain note wear', 'price headphones sound']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B0002CZHN6 ['cable hdmi dvi', 'work great cable', 'work product connect']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B00004TS16 ['battery picture camera', 'recommend realize size', 'zoom fantastically camera produce']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B000204SWE ['play dvds europe', 'play dvd player', 'gift philips player']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B00009WQS1 ['use drive hd', 'use hard drive', 'clone hard drive']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B00066HP7Y ['cable flat screen', 'piece garbage need leave', 'pc car stream far']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B0000AQIFW ['device iriver color', 'good mp3 player', 'sonic product look']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B00005NIMJ ['use trackman mouse', 'use delivery mouse', 'use ball mouse']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B00007GQLU ['price prime lens great', 'great lens reasonable', 'lens f great']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B00018MSNI ['headphone headphones sound', 'close headphones replace', 'headphones sound like']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Topics:\n",
      "B0002KVQBA ['sound sub subwoofer', 'room repair sub', 'huummm subwoofer']\n"
     ]
    }
   ],
   "source": [
    "red_nmf = 0 \n",
    "\n",
    "redundancy_arr = ()\n",
    "\n",
    "for asin in valid_asins:\n",
    "    topics, review = print_topics(asin)\n",
    "    print(asin,topics)\n",
    "    lemmas = ' '.join(lemma for lemma in topics)\n",
    "    temp_red = redundancy(lemmas)\n",
    "    red_nmf += temp_red\n",
    "    redundancy_arr = list(redundancy_arr)\n",
    "    redundancy_arr.append((asin,temp_red))\n",
    "    redundancy_arr = tuple(redundancy_arr)\n",
    "    \n",
    "red_lda = 0 \n",
    "\n",
    "for asin in valid_asins:\n",
    "    topics, review = print_topics_lda(asin)\n",
    "    print(asin, topics)\n",
    "    lemmas = ' '.join(lemma for lemma in topics)\n",
    "    red_lda += redundancy(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('B00030CHRQ', 0.04077160440319583), ('B0002Y5WXO', 0.07270143066184376), ('B0002IOIMQ', 0.0694134639479278), ('B00007M1TZ', 1.1102230246251565e-16), ('B00062UW5A', 0.07689207981130575), ('B000629GES', 0.057669059858479255), ('B0000DJEK7', 4.440892098500626e-16), ('B00006JN3G', 0.0694134639479278), ('B0000BYDKO', 0.10192901100798912), ('B0001NNLHK', -2.220446049250313e-16), ('B00020S7XK', 0.06504864248484399), ('B0002UM0JW', 0.03844603990565287), ('B0002UPGOI', 0.016365081042566065), ('B0002SQ2P2', 0.06885190025657495), ('B00005QXWI', 0.03890705966059538), ('B00017LSPI', 0.04627564263195183), ('B0000C3GWU', 0.13009728496968764), ('B0002D03ZW', 0.0), ('B0002WPSBC', 0.07814669001728858), ('B00028D778', 0.0), ('B00066EK2W', 0.02313782131597597), ('B00004T8R2', 0.04077160440319594), ('B0002CZHN6', 0.08923770245817264), ('B00004TS16', 0.059432742193288424), ('B000204SWE', 0.020385802201598135), ('B00009WQS1', 0.020385802201598135), ('B00066HP7Y', 0.06546032417026526), ('B0000AQIFW', 4.440892098500626e-16), ('B00005NIMJ', 0.057669059858479255), ('B00007GQLU', 0.10841440414140635), ('B00018MSNI', 0.04336576165656281), ('B0002KVQBA', 0.02313782131597597))\n"
     ]
    }
   ],
   "source": [
    "print(redundancy_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg reduncdancy NMF: 0.04757272814138594\n",
      "Avg reduncdancy LDA: 0.14086402562112307\n"
     ]
    }
   ],
   "source": [
    "asins_count = len(valid_asins)\n",
    "\n",
    "avd_red_nmf = red_nmf/asins_count\n",
    "avg_red_lda = red_lda/asins_count\n",
    "\n",
    "print('Avg reduncdancy NMF:', avd_red_nmf)\n",
    "print('Avg reduncdancy LDA:', avg_red_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_tags_df = pd.read_csv('amazon_scraped_tags.csv',keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Product', '# of Reviews', 'ASIN', 'Tags', 'Unnamed: 4', 'Unnamed: 5',\n",
      "       'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10',\n",
      "       'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14',\n",
      "       'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18',\n",
      "       'Unnamed: 19'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASIN</th>\n",
       "      <th>CombinedTags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0002SQ2P2</td>\n",
       "      <td>speaker system sound quality headphone jack sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0002KVQBA</td>\n",
       "      <td>polk audio living room sounds great surround s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00020S7XK</td>\n",
       "      <td>great little pocket radio battery life sound q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B0002D03ZW</td>\n",
       "      <td>earbuds sound quality couple months every 6 mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B0002WPSBC</td>\n",
       "      <td>home theater surround sound speaker system sou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ASIN                                       CombinedTags\n",
       "0  B0002SQ2P2  speaker system sound quality headphone jack sa...\n",
       "1  B0002KVQBA  polk audio living room sounds great surround s...\n",
       "3  B00020S7XK  great little pocket radio battery life sound q...\n",
       "5  B0002D03ZW  earbuds sound quality couple months every 6 mo...\n",
       "6  B0002WPSBC  home theater surround sound speaker system sou..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(scraped_tags_df.columns)\n",
    "\n",
    "tags_df = scraped_tags_df.iloc[: , 2 : 20]\n",
    "tags_df.head(5)\n",
    "\n",
    "tags_df['CombinedTags'] = tags_df[tags_df.columns[1:]].apply(\n",
    "    lambda x: ' '.join(x.dropna().astype(str)),\n",
    "    axis=1\n",
    ")\n",
    "asin_tags_df = tags_df.loc[ : , ['ASIN','CombinedTags'] ]\n",
    "asin_tags_df= asin_tags_df[asin_tags_df.ASIN.isin(valid_asins)]\n",
    "asin_tags_df.to_csv('valid_asin_scraped_tags_df.csv')\n",
    "\n",
    "asin_tags_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B0002SQ2P2', 'B0002KVQBA', 'B00020S7XK', 'B0002D03ZW', 'B0002WPSBC', 'B00006JN3G', 'B0002CZHN6', 'B00004T8R2', 'B00007M1TZ', 'B0002UPGOI', 'B000204SWE', 'B000629GES', 'B00017LSPI', 'B0002UM0JW', 'B0000C3GWU', 'B0001NNLHK', 'B0000BYDKO', 'B00066HP7Y', 'B0000AQIFW', 'B00066EK2W', 'B00005NIMJ', 'B00009WQS1', 'B0000DJEK7', 'B00028D778', 'B00030CHRQ', 'B0002IOIMQ', 'B0002Y5WXO', 'B00062UW5A', 'B00007GQLU', 'B00004TS16', 'B00005QXWI', 'B00018MSNI']\n",
      "Avg reduncdancy NMF: 0.06690723690841899\n"
     ]
    }
   ],
   "source": [
    "valid_asins = list(asin_tags_df['ASIN'])\n",
    "print(valid_asins)\n",
    "review_sentences = list(asin_tags_df['CombinedTags'])\n",
    "redundancy_arr = ()\n",
    "\n",
    "red_amazon_scraped_tags = 0 \n",
    "for i in range(len(review_sentences)):\n",
    "    temp_red = redundancy(review_sentences[i])\n",
    "    red_amazon_scraped_tags += temp_red\n",
    "    redundancy_arr = list(redundancy_arr)\n",
    "    redundancy_arr.append((valid_asins[i],temp_red))\n",
    "    redundancy_arr = tuple(redundancy_arr)\n",
    "    \n",
    "asins_count = len(valid_asins)\n",
    "\n",
    "avd_red_amazon_scraped_tags = red_amazon_scraped_tags/asins_count\n",
    "\n",
    "print('Avg reduncdancy NMF:', avd_red_amazon_scraped_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "print(asins_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('B0002SQ2P2', 0.01722706232293625), ('B0002KVQBA', 0.07407407407407396), ('B00020S7XK', 0.05678533309253431), ('B0002D03ZW', 0.06138624817088656), ('B0002WPSBC', 0.12073246487342737), ('B00006JN3G', 0.11009096747637015), ('B0002CZHN6', 0.044574556644966234), ('B00004T8R2', 0.0837725743386264), ('B00007M1TZ', 0.032730162085132464), ('B0002UPGOI', 0.05000000000000038), ('B000204SWE', 0.014196333273133965), ('B000629GES', 0.15912321167269505), ('B00017LSPI', 0.132598753895238), ('B0002UM0JW', 0.12080961137566348), ('B0000C3GWU', 0.06546032417026526), ('B0001NNLHK', 0.03273016208513235), ('B0000BYDKO', 0.042588999819400786), ('B00066HP7Y', 0.09693609377704371), ('B0000AQIFW', 0.03273016208513235), ('B00066EK2W', 0.04075900941810162), ('B00005NIMJ', 0.029716371096644156), ('B00009WQS1', 0.11381876958331827), ('B0000DJEK7', 6.661338147750939e-16), ('B00028D778', 0.01722706232293625), ('B00030CHRQ', 0.11886548438657696), ('B0002IOIMQ', 0.09263755863796663), ('B0002Y5WXO', 0.06819406190476329), ('B00062UW5A', 0.08664609663791745), ('B00007GQLU', 0.03273016208513235), ('B00004TS16', 0.09053631692101882), ('B00005QXWI', 0.029716371096644156), ('B00018MSNI', 0.07163722174572817))\n"
     ]
    }
   ],
   "source": [
    "print(redundancy_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      " - bass sound music\n",
      " - 2300 z\n",
      " - great sound\n",
      " - buy speakers computer\n",
      " - remote satellite cable\n",
      " - sound good card\n",
      " - work great bose\n",
      " - speaker best set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      " - bass sound music\n",
      " - 10 psw\n",
      " - port want sub\n",
      " - great sound\n",
      " - rca input subwoofer\n",
      " - room live\n",
      " - home theater\n",
      " - price buy product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      " - sony radio fm\n",
      " - great radio little\n",
      " - work fine\n",
      " - use power batteries\n",
      " - quality sound\n",
      " - buy headphones good\n",
      " - station little good\n",
      " - volume control\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      " - headphones sound music\n",
      " - years home studio\n",
      " - head wear ears\n",
      " - comfortable great\n",
      " - flat hz response\n",
      " - price expect feel\n",
      " - read review say\n",
      " - amp headphone fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      " - speaker speakers sound\n",
      " - z 5500\n",
      " - price set speakers\n",
      " - sound great\n",
      " - buy day years\n",
      " - home theater\n",
      " - customer break send\n",
      " - card sound\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      " - use lens pen\n",
      " - camera bag\n",
      " - lenses clean\n",
      " - brush dust end\n",
      " - use carry easy\n",
      " - work product great\n",
      " - lens clean\n",
      " - good job\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      " - cable hdmi dvi\n",
      " - cable work price\n",
      " - laptop monitor computer\n",
      " - quality good\n",
      " - work great\n",
      " - pc connect tv\n",
      " - use xbox 360\n",
      " - work perfect monitor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      " - headphones sound pair\n",
      " - sound good\n",
      " - price work great\n",
      " - use cord long\n",
      " - recommend highly\n",
      " - head fit ear\n",
      " - work fine lightweight\n",
      " - volume buy quality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      " - use headset headsets\n",
      " - cordless phone\n",
      " - quality sound\n",
      " - people hear talk\n",
      " - work great\n",
      " - volume control\n",
      " - set head fit\n",
      " - hand free\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 22\n",
      "Topics: 8\n",
      " - use power wire\n",
      " - amp need install\n",
      " - work cheap great quality\n",
      " - car kit audio\n",
      " - awg watts rms\n",
      " - price thing great\n",
      " - grind length easy\n",
      " - 100 perfect sas bazooka\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      " - dvd player\n",
      " - divx play file\n",
      " - remote region unit\n",
      " - play dvds\n",
      " - months warranty philips\n",
      " - work price great\n",
      " - close button hold stop\n",
      " - dvp 642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      " - cancel noise\n",
      " - set headphones sony\n",
      " - good bose\n",
      " - use ears flight\n",
      " - work fragile advertise\n",
      " - buy product flight long\n",
      " - sony headphones pair\n",
      " - quality sound ear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      " - use blow dust\n",
      " - compress air\n",
      " - work great\n",
      " - camera bag\n",
      " - clean sensor\n",
      " - blaster rocket air\n",
      " - blower good say\n",
      " - lens dust remove\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      " - use button mouse\n",
      " - mx1000 mx700 surface\n",
      " - time wireless track\n",
      " - use click original\n",
      " - life good battery\n",
      " - revolution mx\n",
      " - mac charge easy\n",
      " - great logitech mouse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      " - quality speakers sound\n",
      " - volume control turn\n",
      " - work great\n",
      " - use great sound\n",
      " - mac sound book\n",
      " - save feature\n",
      " - speakers set sound\n",
      " - harman kardon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 23\n",
      "Topics: 8\n",
      " - bass listen music\n",
      " - supply good fit\n",
      " - cord headphones best\n",
      " - noise sound block\n",
      " - bud hear really\n",
      " - seal phone ear\n",
      " - price star earphones\n",
      " - cover plastic wire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      " - cord reel\n",
      " - cable weight reel\n",
      " - plug end male\n",
      " - work great\n",
      " - price like look\n",
      " - 100 cord foot\n",
      " - extension cord easy\n",
      " - time use cord\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 18\n",
      "Topics: 8\n",
      " - sound laptop audio cheep\n",
      " - cable headphones audio\n",
      " - cable work headphones\n",
      " - sound suppose tv\n",
      " - cord great stream\n",
      " - quite sure bite\n",
      " - pc buy car\n",
      " - trick ipod electronic thing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 21\n",
      "Topics: 8\n",
      " - use mp3 player\n",
      " - work run rio\n",
      " - pretty year hours\n",
      " - expandable perfect small\n",
      " - sonic device employee\n",
      " - product stop\n",
      " - know person help\n",
      " - rip cd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      " - play good player\n",
      " - use easy\n",
      " - drive hard\n",
      " - memory mp3 player\n",
      " - music classical\n",
      " - come happy 3\n",
      " - 1 v\n",
      " - button nice small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 23\n",
      "Topics: 8\n",
      " - work use mouse\n",
      " - marble trackman wheel\n",
      " - wireless version wire\n",
      " - track ball\n",
      " - trackball button easy\n",
      " - pad thumb mouse\n",
      " - years logitech 5\n",
      " - thumb button finger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 23\n",
      "Topics: 8\n",
      " - hard drive\n",
      " - work version support\n",
      " - ssd usb drive\n",
      " - use enclosure upgrade\n",
      " - box right\n",
      " - dell hdd clone\n",
      " - connect screw way\n",
      " - partition product like\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 23\n",
      "Topics: 8\n",
      " - use unit roadmate\n",
      " - extend warranty\n",
      " - customer magellan update\n",
      " - battery internal\n",
      " - device save location\n",
      " - wife love door\n",
      " - 2620 disappoint control\n",
      " - destination cities job\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      " - radar detector\n",
      " - x50 cord unit\n",
      " - cop car drive\n",
      " - heat escort service\n",
      " - mount better windshield\n",
      " - protection know expensive\n",
      " - display blue red\n",
      " - work years sensitivity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      " - extension cord length\n",
      " - buy earbuds ears\n",
      " - headphones great ear\n",
      " - expose coat wire\n",
      " - bass buy sony\n",
      " - work pull ear\n",
      " - price use\n",
      " - mp3 player\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      " - 4 charge batteries\n",
      " - charger good right\n",
      " - camera sony batteries\n",
      " - life battery\n",
      " - display lcd\n",
      " - charger fast\n",
      " - years use\n",
      " - die cells sony\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      " - lens kit great\n",
      " - zoom light good\n",
      " - lense print good\n",
      " - canon tamron mm\n",
      " - repair problem canon\n",
      " - purpose lens general\n",
      " - return great amazon\n",
      " - heavy picture big\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      " - box snap case\n",
      " - sleeves good paper\n",
      " - look storage need\n",
      " - box cds easy\n",
      " - assemble easy\n",
      " - price store need\n",
      " - pretty discs paper\n",
      " - dvd size love\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      " - use lens shoot\n",
      " - 85mm f l\n",
      " - f1 8\n",
      " - lens love\n",
      " - purchase lens l\n",
      " - lenses image nice\n",
      " - light low\n",
      " - portraits great lens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 23\n",
      "Topics: 8\n",
      " - use picture camera\n",
      " - larger thing card memory\n",
      " - quality machine paper\n",
      " - work snorkel camera\n",
      " - great overall think little camera\n",
      " - exposure camera stop\n",
      " - glad shoot s100\n",
      " - charger reasonable battery especially\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 23\n",
      "Topics: 8\n",
      " - cd player turn\n",
      " - work plate screw\n",
      " - mp3 far player rangeit price\n",
      " - purchase year little\n",
      " - pay make good\n",
      " - 1 3 2\n",
      " - accessory know player\n",
      " - 100 90 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 23\n",
      "Topics: 8\n",
      " - cable sound headphone\n",
      " - 650 hd\n",
      " - comfortable headphones sound\n",
      " - hd650 headphones ears\n",
      " - amp tube\n",
      " - years ago\n",
      " - use like love\n",
      " - listen hear music\n"
     ]
    }
   ],
   "source": [
    "#add emojis to topics\n",
    "import emoji\n",
    "for asin in valid_asins:\n",
    "    topics, reviews = print_topics(asin)\n",
    "\n",
    "    emoji_topics = []\n",
    "    for topic_id, topic in enumerate(topics):\n",
    "\n",
    "        # grab the average sentiment\n",
    "        product_reviews_df = pd.DataFrame(reviews)\n",
    "\n",
    "        product_reviews_df = product_reviews_df[product_reviews_df['topic'] == topic_id]\n",
    "        polarity   = product_reviews_df['summary_sentiment'].mean()\n",
    "\n",
    "        # append emojis to topic name based on range of sentiment\n",
    "        if polarity <= -0.5:\n",
    "            emoji_topics.append(\" - \"+topic)\n",
    "        elif polarity > -0.5 and polarity < 0.5:\n",
    "            emoji_topics.append(\" - \"+topic)\n",
    "        else:\n",
    "            emoji_topics.append(\" - \"+topic)\n",
    "\n",
    "    for emoji_topic in emoji_topics:\n",
    "        print(emoji.emojize(emoji_topic))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "focal length wide open full frame image quality depth field great lens highly recommend autofocus purple fringe chromatic aberration build quality shallow depth background blur\n",
      "0.03445412464587205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return topics\n",
      "Summary :\n",
      " 24\n",
      "Topics: 8\n",
      "['use lens shoot', '85mm f l', 'f1 8', 'lens love', 'purchase lens l', 'lenses image nice', 'light low', 'portraits great lens']\n",
      "use lens shoot 85mm f l f1 8 lens love purchase lens l lenses image nice light low portraits great lens\n",
      "0.10841440414140635\n"
     ]
    }
   ],
   "source": [
    "string = 'focal length wide open full frame image quality depth of field great lens highly recommend autofocus purple fringing chromatic aberration build quality shallow depth background blur'\n",
    "lemmas = tokenizeText(string) \n",
    "lemmas = ' '.join(lemma for lemma in lemmas)\n",
    "print(lemmas)\n",
    "print(redundancy(lemmas))\n",
    "\n",
    "topics, review = print_topics('B00007GQLU')\n",
    "print(topics)\n",
    "lemmas = ' '.join(lemma for lemma in topics)\n",
    "print(lemmas)\n",
    "print(redundancy(lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
